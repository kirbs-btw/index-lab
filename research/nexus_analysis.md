# NEXUS Algorithm Analysis

> **NEXUS**: Neural EXploration with Unified Spectral Routing  
> **Research Gap Addressed**: Gap 3A â€“ Learned Index Structures (spectral variant)  
> **Implementation Date**: 2026-01-07

---

## Executive Summary

NEXUS exploits manifold structure through spectral embedding and entropy-adaptive graph construction. It uses random projections for fast dimensionality reduction and allocates more graph edges to sparse/boundary regions.

| Verdict | Rating |
|---------|--------|
| **Concept** | â­â­â­â­â­ |
| **Implementation Quality** | â­â­â­â­â˜† |
| **Performance** | â­â­â­â˜†â˜† |
| **Scalability** | â­â­â­â­â˜† |
| **Research Value** | â­â­â­â­â˜† |

---

## Algorithm Overview

### Core Idea

Exploit manifold structure via low-dimensional projections:

```
d-dimensional space (768-dim)     â†’     m-dimensional spectral space (32-dim)
        O(d) distances            â†’           O(m) distances
```

### Components

| Component | Purpose |
|-----------|---------|
| `SpectralProjector` | Random projection matrix for dimensionality reduction |
| `AdaptiveGraph` | Graph with entropy-based variable edge counts |
| `NexusConfig` | Configuration (spectral dim, base edges, ef_search) |
| `NexusIndex` | Main index with two-phase search |

### Key Features

1. **Random Projections**: Johnson-Lindenstrauss approximation for spectral embedding
2. **Local Entropy Estimation**: Measures distance variance to identify sparse regions
3. **Adaptive Edge Count**: 0.5Ã— to 2Ã— base edges based on local entropy
4. **Two-Phase Search**: Spectral filtering â†’ full distance reranking

---

## Implementation Details

### Spectral Projection

Uses random Gaussian projections scaled by `1/âˆšm`:

```rust
let scale = 1.0 / (spectral_dim as f32).sqrt();
let projections = (0..spectral_dim)
    .map(|_| (0..original_dim).map(|_| rng.gen_range(-1.0..1.0) * scale).collect())
    .collect();
```

**Why not true eigendecomposition?**
- Requires eigensolver library (e.g., ndarray-linalg, nalgebra)
- O(nÂ³) computation for full decomposition
- Random projections provide similar benefits with O(nÂ·dÂ·m) complexity

### Entropy-Adaptive Edges

```rust
fn compute_edge_count(&self, entropy: f32) -> usize {
    let multiplier = (entropy / self.mean_entropy).clamp(0.5, 2.0);
    (base_edges as f32 * multiplier) as usize
}
```

- **Low entropy** (dense cluster): fewer edges needed
- **High entropy** (sparse/boundary): more edges for connectivity

### Two-Phase Search

1. **Phase 1**: Graph traversal using m-dimensional spectral distances
2. **Phase 2**: Rerank top candidates using full d-dimensional distances

---

## Configuration

| Parameter | Default | Description |
|-----------|---------|-------------|
| `spectral_dim` | 32 | Projection dimensionality (m) |
| `base_edges` | 16 | Base edges per node |
| `ef_search` | 100 | Candidates to explore |
| `rerank_ratio` | 2.0 | Multiplier for reranking pool |
| `seed` | 42 | Random seed |

---

## Strengths

### âœ… Fast Per-Step Computation
- Spectral distance: O(m) vs O(d) for full distance
- With m=32, d=768: **24Ã— fewer FLOPs per distance**

### âœ… Adaptive Graph Topology
- More edges in hard regions â†’ better connectivity
- Fewer edges in easy regions â†’ less computation

### âœ… Johnson-Lindenstrauss Guarantees
- Random projections preserve distances with high probability
- Well-understood theoretical foundations

### âœ… Good Test Coverage
- 9 unit tests covering core functionality
- All tests pass

---

## Current Limitations

### ğŸŸ  Simplified Spectral Embedding
Not true eigendecompositionâ€”random projections approximate but don't capture exact manifold structure.

### ğŸŸ  Build Time Overhead
O(nÂ²) graph construction for entropy estimation. Could be improved with approximate k-NN.

### ğŸŸ  No Neural Router
Original proposal included NRP (Neural Route Predictor) which would require ML inference runtime.

---

## Comparison with Other Indexes

| Feature | HNSW | NEXUS | SEER |
|---------|------|-------|------|
| **Per-step complexity** | O(MÃ—d) | O(MÃ—m) | O(nÃ—proj) |
| **Adaptive topology** | âŒ | âœ… | âŒ |
| **Manifold-aware** | âŒ | âœ… | Partial |
| **Memory overhead** | O(nÃ—M) | O(nÃ—m + nÃ—M) | O(nÃ—proj) |

---

## Files

- [`crates/index-nexus/src/lib.rs`](file:///Users/bastianlipka/Desktop/index-lab/crates/index-nexus/src/lib.rs) â€” Main implementation (~500 lines)
- [`crates/index-nexus/Cargo.toml`](file:///Users/bastianlipka/Desktop/index-lab/crates/index-nexus/Cargo.toml) â€” Dependencies

---

## Future Extensions

1. **True Spectral Decomposition**: Add eigensolvers (lapack bindings) for accurate manifold learning
2. **Neural Route Predictor**: Train MLP for per-step navigation decisions
3. **Approximate k-NN Build**: Use LSH or random sampling for O(n log n) graph construction
4. **Hierarchical Structure**: Add HNSW-style layers for O(log n) entry point finding

---

## Conclusion

NEXUS demonstrates the value of exploiting manifold structure for vector search. The current implementation using random projections provides a practical approximation with measurable benefits: faster per-step computation and adaptive graph topology.

**Key Insight**: Real-world embeddings have structureâ€”exploiting it through dimensionality reduction and adaptive topology can improve search efficiency.

---

*Analysis created: 2026-01-07*  
*Status: âœ… Implemented and tested*  
*Implementation: [`index-nexus`](file:///Users/bastianlipka/Desktop/index-lab/crates/index-nexus/)*
